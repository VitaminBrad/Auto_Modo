{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-Ready Reformatting of Experimental Data  \n",
    "\n",
    "1. Request file from a URL (presumably published expiermental data)\n",
    "and do any of the following if necessary:\n",
    "  1. Extract them from a zipped file, \n",
    "  2. Convert them from a excel formats (.xls, .xlsx) - needs 10 minute clean-up\n",
    "2. Upload the file to OpenRefine via its API\n",
    "3. Perform clean-up operations in Open Refine\n",
    "4. Download the data\n",
    "\n",
    "Future Directions:\n",
    "\n",
    "5. Run the data on the model\n",
    "6. Return model output and whether it agrees/disagrees with experiment (implicitly recommended a change in model or experiment)\n",
    "7. Then either:\n",
    "    1. Recommend necessary conditions for similar results or for a particular (user-defined) output to occur\n",
    "    2. Allow for the observation of different model outputs with theoretically different inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "import json # Do https://developer.rhino3d.com/guides/rhinopython/python-xml-json/\n",
    "from IPython.display import HTML\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import os\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Be sure to use the link (\"copy link address\") as the raw! Not \"download\"\n",
    "URL = 'https://doi.org/10.1371/journal.pcbi.1006680.s004'\n",
    "if not (sys.argv[0]): URL = sys.argv[0]\n",
    "    \n",
    "items = URL.split(\"/\")\n",
    "file_name_parts = items[-1].split(\"?\")\n",
    "file_name = file_name_parts[0] + \".zip\" #req: control statment to check if zip or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/benglish/Auto_Modo\\\\journal.pcbi.1006680.s004.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-340003bfdc95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpath_to_zip_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcwd\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\\\'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#unzip zipped files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mzip_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_zip_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#Create folder to download into based on name of download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_extract_dest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_extract\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/condaenv/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/benglish/Auto_Modo\\\\journal.pcbi.1006680.s004.zip'"
     ]
    }
   ],
   "source": [
    "#with urllib\n",
    "urllib.request.urlretrieve(URL, file_name)\n",
    "cwd = os.getcwd()\n",
    "\n",
    "path_to_zip_file = cwd + '\\\\' + file_name \n",
    "#unzip zipped files\n",
    "zip_ref = zipfile.ZipFile(path_to_zip_file, 'r')\n",
    "#Create folder to download into based on name of download\n",
    "if not(os.path.exists(zip_extract_dest)): os.mkdir(file_name+\"_extract\")\n",
    "zip_extract_dest = cwd + '\\\\' +file_name + \"_extract\"\n",
    "zip_ref.extractall(zip_extract_dest) #directory to extract to\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Project\n",
    "file_ext,i = \"\",0\n",
    "API_URL = \"http://127.0.0.1:3333/command/core/create-project-from-upload\"\n",
    "\n",
    "#Jimmy-rigged method to determine file extension:\n",
    "file_name_back = file_name[::-1]\n",
    "while True:\n",
    "    file_ext += file_name_back[i]\n",
    "    if file_name_back[i] == '.': break \n",
    "    i += 1\n",
    "file_ext = file_ext[::-1] #flip file extension to read in correct direction\n",
    "\n",
    "\n",
    "#iterate through extracted zip folder to experimental data\n",
    "for currentFile in os.listdir(zip_extract_dest):\n",
    "    total_file_path = zip_extract_dest+'\\\\'+currentFile\n",
    "    if currentFile.endswith(\".txt\"): \n",
    "        df = pd.read_csv(total_file_path, sep='\\t', lineterminator='\\n')\n",
    "        csv = df.to_csv(sep='\\t', float_format='%.3f')\n",
    "        tsv = csv.replace(',','\\t')\n",
    "        upload_file_name = total_file_path[0:-len(file_ext)] + '.tsv'\n",
    "        continue\n",
    "    elif currentFile.endswith(\".xls\") or currentFile.endswith(\".xlsx\"):\n",
    "        df = pd.read_excel(os.cwd)\n",
    "        csv = df.to_csv()\n",
    "        tsv = csv.replace(',','\\t')\n",
    "        continue\n",
    "print(upload_file_name)\n",
    "with open(upload_file_name, 'w') as wf:\n",
    "    wf.write(\"\" + tsv)\n",
    "#tsv, put it in below \n",
    "data = {'project-file':(upload_file_name, open(upload_file_name, 'r'), 'application/vnd.ms-excel', {'Expires': '0'}), \n",
    "       }\n",
    "\n",
    "# sending post request and saving response as response object \n",
    "r = requests.post(url = API_URL, files = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Project\n",
    "\n",
    "getURL = \"http://127.0.0.1:3333/command/core/get-models\"\n",
    "getData = {'project': '2432443441126'}\n",
    "g = requests.get(url = getURL, params = getData)\n",
    "json_obj = g.json()\n",
    "-    json.dump(json_obj, outfile)\n",
    "g.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Operations (Remove Column 'time')\n",
    "project_id_remove = '1659010586174'\n",
    "ops_url = \"http://127.0.0.1:3333/command/core/apply-operations?\" \n",
    "json_ops = [\n",
    "  {\n",
    "    \"op\": \"core/column-removal\",\n",
    "    \"description\": \"Remove column time\",\n",
    "    \"columnName\": \"time\"\n",
    "  }\n",
    "]\n",
    "\n",
    "opsData = {'project': project_id_remove,\n",
    "          'operations': json.dumps(json_ops)}\n",
    "\n",
    "op = requests.post(url = ops_url,  data = opsData)\n",
    "op.status_code\n",
    "HTML(op.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete Project\n",
    "#Apply Operations - Remove\n",
    "project_id_delete = '2432443441126'\n",
    "ops_url = \"http://127.0.0.1:3333/command/core/delete-project\" \n",
    "\n",
    "op = requests.post(url = ops_url, data = opsData)\n",
    "op.status_code\n",
    "HTML()\n",
    "op.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
